---
title: "SORT-seq dataset with velocity preparations"
params:
  method: 
    label: "method -- experimental method"
    choices: ['plate', 'droplet']
    value: 'plate'
  kb.dir: 
    label: "kb.dir -- Directory containing kb-python output"
    value: /Users/tilman_work/Documents/Projects/R/testset/kallistobus
  barcode_file: 
    label: "barcode_file -- .tab delimited file with barcode sequences. Use 2-col layout for plate based methods"
    value: /Users/tilman_work/Documents/Projects/R/scRNA-seq/data/barcode_384.tab
  mt_genes_file:
    label: "mt_genes_file -- .txt file containing mitchondrial gene names"
    value: /Users/tilman_work/Documents/Projects/R/scRNA-seq/data/MT_genes.txt
  meta_data:
    label: "meta_data -- .csv file containing cell meta data. Alternative for extract_meta_columns"
    value: "" #/Users/tilman_work/Documents/Projects/R/scRNA-seq/data/pbmc_meta_test.csv  #used when extract_phenotypes = FALSE
  extract_meta_columns: 
    label: "extract_meta_columns -- extracts meta data from sample names. Alternative for meta_data."
    value: Genome,Method,Lineage,Timepoint,Replicate,Library,Well
  resultsdir:
     label: "resultsdir -- output directory for qc files" 
     value: /Users/tilman_work/Documents/Projects/R/scRNA-seq/output
  meta_group_id: 
      label: "meta_group_id -- combine meta data fields for plotting (seperated multiple values by comma)" 
      value: Library
  umap_cols: 
      label: "umap_cols -- meta data fields for Seurat's RunUMAP (seperated multiple values by comma)"
      value: Method  
  confounders_to_test: 
      label: "confounders_to_test -- meta data variabel for confounder testing (seperated multiple values by comma)"
      value: Library
  lab_col: 
      label: "lab_col -- Library meta data field"
      value: Library
  add.spikes.ercc: 
      label: "add.spikes.ercc -- use ercc spike-ins (if present)"
      value: true
  ercc_pct_max: 
      label: "ercc_pct_max -- max percentage ercc spike-ins"
      value: 20
  add.spikes.mt: 
      label: " add.spikes.mt -- use mitochondrial gene-list for qc"
      value: true
  mt_pct_max: 
      label: "mt_pct_max -- max percentage mitochondrial genes"
      value: 50
  amount_cells_expr: 
      label: "amount_cells_expr -- threshold for amount of cells considered expressed"
      value: 0
  total_counts_tresh: 
      label: "total_counts_tresh -- threshold for total UMI counts"
      value: 1000
  total_feat_tresh: 
      label: "total_feat_tresh -- threshold for total number of feature (genes) per proportion of cells"
      value: 500
  gene_tresh: 
      label: "gene_tresh -- threshold for total number of genes after qc"
      value: 0
  nhvg: 
      label: "nhvg -- number of genes for Seurat's FindVariableFeatures"
      value: 2000
  cell_id_filter_option: 
      label: "cell_id_subset_filter -- filter options for cell_id_subset" 
      choices: ['in', 'out', 'none']
      value: 'none'    
  cell_id_filter_pattern: 
      label: "cell_id_subset -- cell ids to include/exclude based on cell_id_subset_filter"
      value: _A9    
  pcs_for_overview:
      label: "pcs_for_overview -- principal components for overview in combined umap plot"
      value: '10,20,30,40,50'
  pcs_max_hvg: 
      label: "pcs_max_hvg -- max number of principal components to visualize"
      value: 70
  vars_to_regress_sf:
      label: "vars_to_regress -- variables to perform regression analysis (spliced)"
      value:  nCount_sf
  vars_to_regress_uf:
      label: "vars_to_regress -- variables to perform regression analysis (unspliced)"
      value:  nCount_uf
  new_col_pattern:
      label: "new_col_pattern -- new column pattern"
      value: ""
  old_col_pattern: 
      label: "old_col_pattern -- old column pattern"
      value: ""


output:
  pdf_document:
    pandoc_args: --listings
    includes:
      in_header: preamble.tex
    toc: true
    toc_depth: 2
    number_sections: true
---
```{r include = FALSE}
#Custom listings markdown template: https://stackoverflow.com/questions/21402157/colour-for-r-code-chunk-in-listings-package/21468454

# Plate based assays:
 # Make sure the plates to combine all have the same amount of "_" separated fields in their folder names.
 # These fields will be used to set up the phenodata columns. - The Combined ID per plate, will be used for labelling in figures.
# Droplet based assay (experimental)
 # You can provide custom meta-data if you dont want to derive the phenotype fields from sample names when extract_phenotypes is set to FALSE.
 # Set up a .csv file with minimally the following base columns: Sample,Genome,Barcode,Library.
 # The sample,genome and barcode columns will be combined to match the barcode ids in the spliced/unspliced count matrix.
 # Additional columns can be provided for statistical analysis, such as umap embeddings. An example can be found in the data folder (pbmc_meta_test.csv).
 # Set the meta_data parameter to the path of the csv file
here::set_here()
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
source(here::here("utils.R"),local = knitr::knit_global())
system(paste("mkdir -p ", params$resultsdir))
# Loading the important repositories #
require("devtools")
library(ggplot2)
library(dplyr)
library(tidyr)
library(mvoutlier)
library(limma)
library(knitr)
library(SingleCellExperiment)
library(scater)
library(Seurat)
library(scran)
library(RColorBrewer)
library(plot3D)
## unlist parameters ##
label.vector = unlist(strsplit(params$umap_cols,","))
# Unique combined ID per plate, for visualization purposes
extract_meta_columns = unlist(strsplit(params$extract_meta_columns,","))
# Combined columns for plotting in meta data
meta_group_id = unlist(strsplit(params$meta_group_id,","))
# PCs used for different UMAP representations
pcs_for_overview = as.integer(unlist(strsplit(params$pcs_for_overview,",")))
#Checking variability explained by confounding factors
confounders_to_test = unlist(strsplit(params$confounders_to_test,","))
# Marker genes for violin plots
#explore_violin = c("SOX2","GAPDH")
# Regression performed on the following variables:"
vars_to_regress_sf = unlist(strsplit(params$vars_to_regress_sf,","))
vars_to_regress_uf = unlist(strsplit(params$vars_to_regress_uf,","))
#### Small sanitychecks #####
if (params$extract_meta_columns != "" && params$meta_data !="") {
  stop("Provider either a meta-data.csv file or set extract_meta_columns but not both!")
}



```
## *Cleaning up the counts table, for subset: `r params$cell_id_subset`*

----------------------------------------------------------------------

### Creating the SingleCellExperiment object

The counts table is loaded along with the metadata of the cells within an
Scater usable object. Scater will be used to look into the quality of the data
and to help with filtering out bad cells or genes.

Location of the file:
```{r loading dataset, echo=TRUE, message=FALSE, warning=FALSE}
## Splice seperated dataset: 
# Optional edits on cell names: This only runs if a
# substring that needs replacement was defined in parameters (old_col_pattern):
remove_bc = FALSE
if (params$method == "plate") {
  remove_bc = TRUE
}
spliced.data.df = read_kb_counts(
  params$kb.dir,
  "spliced",
  barcode_file = params$barcode_file,
  remove_bc = remove_bc,
  replace_col_old = params$old_col_pattern,
  replace_col_with = params$new_col_pattern
  )
unspliced.data.df = read_kb_counts(
params$kb.dir,
"unspliced",
barcode_file = params$barcode_file,
remove_bc = remove_bc,
replace_col_old = params$old_col_pattern,
replace_col_with = params$new_col_pattern
)
```

```{r}
# Make columnnames the same (order) between matrices
all_cells <- intersect(colnames(spliced.data.df),colnames(unspliced.data.df))
unspliced.data.df <- unspliced.data.df[,all_cells]
spliced.data.df <- spliced.data.df[,all_cells]

# Percentage of reads unspliced
perc_spliced <- round((sum(unspliced.data.df)/(sum(spliced.data.df)+sum(unspliced.data.df)))*100,2)
sprintf("%s%% of the reads are unspliced",perc_spliced)

# The default data.df will be the spliced dataset (shorter to type)
ifelse(!identical(colnames(spliced.data.df), colnames(unspliced.data.df)),
       stop("Different colnames between sf/uf"),
       "Matching colnames sf/uf")
data.df <- spliced.data.df
```

### Perform subsetting of dataset (optional)
```{r filtering certain entries}

if (params$cell_id_filter_option == "out"){
  # checking the amount of cells in the dataset before filtering
  length(colnames(data.df))
  # the amount of cells you retrieve with the filter.
  length(colnames(data.df[,!grepl(params$cell_id_filter_pattern, colnames(data.df)) == TRUE]))
  # filter cells based on the substring.
  data.df <- data.df[,!grepl(params$cell_id_filter_pattern, colnames(data.df)) == TRUE]
} else if (params$cell_id_filter_option == "in"){
  # checking the amount of cells in the dataset before filtering
  length(colnames(data.df))
  # the amount of cells you retrieve with the filter.
  length(colnames(data.df[,grepl(params$cell_id_filter_pattern, colnames(data.df)) == TRUE]))
  # filter cells based on the substring.
  data.df <- data.df[,grepl(params$cell_id_filter_pattern, colnames(data.df)) == TRUE]
} else {
  print(paste0("No filtering applied. The amount of cells in the dataset remain: ", 
               as.character(length(colnames(data.df)))))
}

spliced.data.df <- data.df
subset_cells <- intersect(colnames(spliced.data.df), colnames(unspliced.data.df))
unspliced.data.df <- unspliced.data.df[,subset_cells]

# no. of plates:
n_bc <- length(readLines(file(params$barcode_file)))
sprintf("%s barcodes in white-list!",n_bc)
if (params$method == "plate") {
  sprintf("%s plates found!",length(colnames(spliced.data.df))/n_bc)
}


```


```{r phenotable}
## Setting up the phenotable ##
if (params$extract_meta_columns != "") {
  phenodata_all <- extract_meta_data(cell.names = colnames(data.df),
                                  group_id = meta_group_id, 
                                  meta_cols= extract_meta_columns)
  phenodata <- phenodata_all[[1]]
  pheno_matched <- phenodata_all[[2]]
  pheno_len <- phenodata_all[[3]]
  if (!identical(rownames(phenodata), colnames(spliced.data.df))) {
      stop("meta-data row names and cell ids are different")
  }
  write.csv(phenodata, paste(params$resultsdir,"phenodata_kbordered.csv", sep="/"))
} else {
  phenodata_all <- read_meta_data(path = params$meta_data,
                                  cell.names = colnames(data.df),
                                  group_id = meta_group_id,
                                  lab_col = params$lab_col)
  phenodata <- phenodata_all[[1]]
  pheno_matched <- phenodata_all[[2]]
  pheno_len <- phenodata_all[[3]]
  #Sanity check
  if (!identical(rownames(phenodata), colnames(spliced.data.df))) {
      stop("meta-data row names and cell ids are different")
  }
}

```

## Plate Overviews

Running QC over the plates: are there

```{r}
if (params$method == "plate") {
  ## Running plate QC: are there certain patterns?
  out.file <- paste(params$resultsdir,"PlateDiag_lndscp.pdf",sep="/")
  plate_qc(data.df = data.df,
           barcode_file = params$barcode_file, 
           spliced.data.df = spliced.data.df, 
           out.file = out.file )
  # # Make a list of cell-names compatable with the excel file: plate#_A1, plate#_A2 etc.
  dev.off()
} else {
  print("No plate QC performed!")
}
```

#### Creating a SingleCellExperiment object for confounder check

```{r build SCE}
# df -> matrix + phenodata -> SCE
#count_matrix <- as.matrix(data.df)
sce <- SingleCellExperiment(assays = list(counts = data.df), 
                            colData = phenodata, 
                            rowData = rownames(data.df))
```

```{r filtering empty entries, echo = FALSE, linewidth=60}
# Checking if the dataset contains genes without a symbol name:
missing.name <- rownames(sce[is.na(rownames(counts(sce)))])
print(missing.name)
```

## Cleaning the expression matrix

Setting thresholds for the removal of genes too lowly expressed in too few
cells.

```{r}
# Filtering on genes considered expressed: above a treshold for a set amount of cells:
control_features <- vector("list", 0)
# Adding spike-in information: (Testing)
if (params$add.spikes.mt) {
  MT_genes <- read.table(params$mt_genes_file)[,1]
  isSpike(sce, "MT") <- rownames(sce)[rownames(sce) %in% MT_genes]
  control_features[["MT"]] <- isSpike(sce, "MT")
}
if (params$add.spikes.ercc) {
  isSpike(sce, "ERCC") <- grepl("^ERCC-", rownames(sce))
    control_features[["ERCC"]] <- isSpike(sce, "ERCC")
}
# Calculate the quality metrics:
sce <- calculateQCMetrics(
  sce, feature_controls = control_features )

# Removal of cells causing a warning:
NaN_cells <- unique(c(colnames(sce)[sce$pct_counts_ERCC == "NaN"],
                        colnames(sce)[sce$pct_counts_MT == "NaN"]))
sce <- sce[,!colnames(counts(sce)) %in% NaN_cells]

```
#### Distribution of counts per cell in the dataset

Manually setting arbitrary count tresholds for the cells considered healthy.

```{r}
# Looking at the total number of RNA molecules per sample
# UMI counts were used for this experiment
hist(sce$total_counts, breaks = 100)
abline(v = params$total_counts_tresh, col = "red")

# Looking at the amount of unique genes per sample
# This is the amount with ERCC included.
hist(sce$total_features_by_counts, breaks = 100)
abline(v= params$total_feat_tresh, col = "red")
```

Histogram showing the total amounts of counts (x-axis) per proportion of cells
(each bar). Red line at: `r params$total_counts_tresh` counts.  Histogram
showing the total amounts of genes (features) per proportion of cells. Red line
at: `r params$total_feat_tresh` genes.

#### Plotting spike-in data

Spike-ins and mitochondrial expression are used as another measure for quality
of the cells. A overrepresentation of spikes and mitochondrial transcript might
indicate a "unhealthy" cell or poor library. These plots show the percentage of
spike-ins against the total amount of reads that are found in each cell.

A higher percentage of spike-in indicates a lower amount of endogenous genes
found in the cell or in case of mitochondrial genes, a cell that was apoptotic.
Also cells that are smaller will have relatively more spike-in allocated reads,
and some cell types might have higher numbers of mitochondria, which is
important to consider setting this boundary.

```{r}
# Using Scater to plot percentages of spikes
# Only works if meta data available.
plot.list = list(
  p1 = plotColData(sce, y = "total_counts", x = params$lab_col),
  p2 = plotColData(sce, y = "total_features_by_counts", x = params$lab_col)
  )
# Add ERCC to multiplot if present
if (params$add.spikes.ercc) {
  plot.list[['p3']] <- plotColData(sce,
            x = "total_features_by_counts",
            y = "pct_counts_ERCC", colour = params$lab_col)
}
if (params$add.spikes.mt) {
  plot.list[['p4']] <- plotColData(sce,
            x = "total_features_by_counts",
            y = "pct_counts_MT", colour = params$lab_col)
}
multiplot( plotlist = plot.list, cols=2)

```

Plotting the percentages of the spike-ins against the total amount of genes,
each dot represents a cell. Color labelled on `r params$lab_col`.

#------------------------------------------
## Filtering of death or unhealthy cells ##
#------------------------------------------

Using manual thresholds for filtering out the outliers in the dataset and using
an automatic approach, based on a PCA on the quality metrics.

```{r}
#---------------------------
## Manually set thresholds for filtering of the cells:
#---------------------------
# Filter library-size and the total amount of genes on the thresholds shown
# above in the histogram.
base.filters <- c("filter_by_expr_features",
                  "filter_by_total_counts", 
                  "filter_by_ercc", 
                  "filter_by_mt")
filters <- vector("list",length(base.filters))
names(filters) <- base.filters
#Add base filters
filters[["filter_by_expr_features"]] <-
  sce$total_features_by_counts >= params$total_feat_tresh
filters[["filter_by_total_counts"]] <-
  sce$total_counts >= params$total_counts_tresh
  #Optional filter conditions
if (params$add.spikes.ercc) {
  filters[["filter_by_ercc"]] <-
    sce$pct_counts_ERCC < params$ercc_pct_max
}
if (params$add.spikes.mt) {
  filters[["filter_by_mt"]] <- 
    sce$pct_counts_MT < params$mt_pct_max
}
#Reduce filtered logis
sce$use <- Reduce("&", Filter(Negate(is.null), filters))
# Amount of cells removed per filtering:
table(filters[["filter_by_expr_features"]])
table(filters[["filter_by_total_counts"]])
table(filters[["filter_by_ercc"]])
table(filters[["filter_by_mt"]])
# Result of manual filtering with set tresholds
# TRUE are considered healthy cells:
table(sce$use)
```

```{r filter cells}
# The quality check-passing cells are stored in the SCE-object in $use selection
# of the counts table.

# Create the quality-checked dataset:
sce_qc <- sce[, colData(sce)$use]
dim(sce_qc)
```

#------------------------
## Filtering the genes ##
#------------------------
```{r filter genes,  linewidth=60}
#---------------------------
## Filtering the genes
#---------------------------
# You do the filtering of the genes after selecting the healthy cells, because
# some genes might only be detected in poor quality cells

# Create the quality-checked dataset:
keep_feature <- rowSums(counts(sce_qc) >= params$gene_tresh) >= params$amount_cells_expr
sce_qc <- sce_qc[keep_feature,]
genes_expressed <- sum(keep_feature==TRUE)
write.table(paste(params$resultsdir,"spliced_qc_counts.tsv",sep="/"), col.names = NA, quote = FALSE)
saveRDS(sce_qc, file = paste(params$resultsdir,"spliced_qc_counts.rds",sep="/"))
```
Plotting the distributions of the dataset before and after filtering.

```{r filtered dataset: compare before/after filtering}

#saveRDS(sce, file = "qc_counts.rds")

pdf(paste(params$resultsdir,"Histograms_before+aftercellsFiltering.pdf",sep="/"))
par(mfrow=c(2,2))
hist(sce$total_counts, breaks = 100)
abline(v = params$total_counts_tresh, col = "red")

hist(sce$total_features_by_counts, breaks = 100)
abline(v= params$total_feat_tresh, col = "red")

hist(sce_qc$total_counts, breaks = 100)
abline(v = params$total_counts_tresh, col = "red")

hist(sce_qc$total_features_by_counts, breaks = 100)
abline(v= params$total_feat_tresh, col = "red")
dev.off()
#Create MT plot before and after filtering
if(params$add.spikes.mt) {
  pdf(paste(params$resultsdir,"MT_before+aftercellsFiltering.pdf", sep="/"))
  par(mfrow=c(2,2))
  print(plotColData(sce,
              x = "total_features_by_counts",
              y = "pct_counts_MT", colour = params$lab_col))

  print(plotColData(sce_qc,
              x = "total_features_by_counts",
              y = "pct_counts_MT", colour = params$lab_col))
  dev.off()
}

#Create ERCC plot before and after filltering
if (params$add.spikes.ercc) {
  pdf(paste(params$resultsdir,"ERCC_before+aftercellsFiltering.pdf", sep="/"))
  par(mfrow=c(2,2))

  print(plotColData(sce,
              x = "total_features_by_counts",
              y = "pct_counts_ERCC", colour = params$lab_col))
  print(plotColData(sce_qc,
              x = "total_features_by_counts",
              y = "pct_counts_ERCC", colour = params$lab_col))
  dev.off()
}
```

In the dataset `r genes_expressed` are considered expressed.

## Check for confounding factors

PCA on only the endogenous genes is used to evaluate the influence of the
confounding factors.

```{r endogenous dataset for confounding factors}
#------------------------------
# Filter endogenous (add scenario for alle qc combinaties)
#------------------------------
# load the filtered dataset:
#sce_qc <- readRDS("qc_counts.rds")

endo_genes <- !rowData(sce_qc)$is_feature_control
table(endo_genes)

# Make a object with only the endogenous genes to look for confounders
sce_endo <- sce_qc[endo_genes,]
reducedDim(sce_qc) <- NULL

# vignette-qc.html#identifying-outliers-on-all-qc-metrics
plotExprsFreqVsMean(sce_endo)

```
```{r,  linewidth=60}
# The reads consumed by the top 50 expressed genes:
plotHighestExprs(sce_qc)
```
Summary of filtering genes: Genes that had less than `r params$amount_cells_expr` cells with an expression less than `r params$gene_tresh`. 
For the genes in this dataset genes that were removed `r table(keep_feature)` genes were kept. Spikes: `r spikeNames(sce)` were saved in
the dataset and used for quality metrics calculations.
```{r PCA on raw data}
# Plotting the raw data without any transformation.
sce_endo <- runPCA(
  sce_endo,
  ncomponents = 50,
  exprs_values = "counts"
)
plotReducedDim(sce_endo, use_dimred = "PCA",
               colour_by = params$lab_col,
               size_by = "total_features_by_counts")

# The PCA data is stored in the reducedDimNames as a "PCA_coldata" entry, if
# use_coldata = TRUE in runPCA(). If use_coldata = FALSE, this will be stored in
# "PCA"
reducedDimNames(sce_endo)

```

# Raw log2-transformation
To compare with other normalization methods.

```{r raw log2-transformation}
assay(sce_endo, "logcounts_raw") <- log2(counts(sce_endo) + 1)

# plotReducedDim and plotPCA will do the same, with plotPCA you leave out the
# use_dimred="PCA" argument.
tmp <- runPCA(sce_endo, 
              ncomponents = 50, 
              exprs_values = "logcounts_raw")
# plot PCA after log2 transformation
plotPCA(tmp,
        colour_by = params$lab_col,
        size_by = "total_features_by_counts")
# One can also run tSNE in similar ways with Scater.
rm(tmp)
# The logcounts_raw is not enough to account for the technical factors between
# the cells.
```

## Normalization in Seurat
Make the seurat object, 'seuset'. In this step you could filter the cells
again, these however already have been filtered before in 'table clean-up',
where the genes were taken that have >2 cells that have an expression >1.

```{r create seurat object}
seuset <-
  CreateSeuratObject(
  counts = counts(sce_endo),
  assay = "sf",
  meta.data = as.data.frame(colData(sce_endo)[, 1:(pheno_len + 1)])
  )
```

```{r}
# looking into the dataset
VlnPlot(
    object = seuset,
    features = c("nFeature_sf"),
    group.by = params$lab_col
)
VlnPlot(
    object = seuset,
    features = c("nCount_sf"),
    group.by = params$lab_col
)
#VlnPlot(
#  object = seuset,
#    features = explore_violin,
#    group.by = params$lab_col
#)
FeatureScatter(
    object = seuset,
    feature1 = "nCount_sf",
    feature2 = "nFeature_sf"
)

```

```{r}
# Seurat normalization: "a global-scaling normalization method LogNormalize that
# normalizes the gene expression measurements for each cell by the total
# expression, multiplies this by a scale factor (10,000 by default), and
# log-transforms the result.""
seu <- seuset
seuset <- NormalizeData(
    object = seuset,
    normalization.method = "LogNormalize",
    scale.factor = 10000
)
# looking into the dataset
VlnPlot(
    object = seuset,
    features = c("nFeature_sf"),
    group.by = params$lab_col
)
VlnPlot(
    object = seuset,
    features = c("nCount_sf"),
    group.by = params$lab_col
)
#VlnPlot(
#  object = seuset,
#    features = explore_violin,
#    group.by = params$lab_col
#)
FeatureScatter(
    object = seuset,
    feature1 = "nCount_sf",
    feature2 = "nFeature_sf"
)
saveRDS(seuset, paste(params$resultsdir,"seuset_qc+norm.rds",sep="/"))
```

#### Check confounders before & after normalization

```{r seurat objects to sce}
# Only take the entries that are matchable with the counttable entries:
filtered_cells <- intersect(rownames(phenodata), 
                            colnames(seuset@assays$sf@data))
pheno_matchedseuset <- phenodata[filtered_cells, ]
pheno_orderedseuset <-
pheno_matchedseuset[match(colnames(seuset@assays$sf@data),
rownames(pheno_matchedseuset)), ]

count_matrixseuset <- as.matrix(seuset@assays$sf@data)

sce_seunorm <-
SingleCellExperiment(
assays = list(counts = count_matrixseuset),
colData = pheno_orderedseuset,
rowData = rownames(count_matrixseuset)
)

# A little trick to let scater know that there are actually logcounts in the dataset.
assay(sce_seunorm, "logcounts") <- counts(sce_seunorm)

# Calculate the quality metrics:
sce_seunorm <- calculateQCMetrics(
  sce_seunorm)

```

# Identifying the variation caused by each confounding factor
#### Before & after normalization

```{r check confounders in raw dataset}

explanatory_variables <- as.factor(c(confounders_to_test, 
                                     "total_features_by_counts", "total_counts"))
#explanatory_variables_seu <- c("total_features_by_counts", "total_counts",
#confounders_to_test)

# This function and visualization performs a PCA analysis in the data object and
# checks to what extend the variables that are put in, are explaining the
# variance. The percentage of variance explained by each variable of interest:

# Setting the colours:
colourvector <- c()
colourset <- brewer.pal(length(explanatory_variables),"Dark2")
i <- 1
for (variable_item in explanatory_variables){
  colourvector[variable_item] <- colourset[i]
  i <- i + 1
}

# Building combined plot, before and after normalization
p1 <- plotExplanatoryVariables(sce_endo,
                               exprs_values = "counts",
                               variables = explanatory_variables) + 
                               expand_limits(y = 1) + 
                               scale_color_manual(values = colourvector) + 
                               ggtitle("Explanatory Variables Before Normalization")
p2 <- plotExplanatoryVariables(sce_seunorm,
                               variables = explanatory_variables) + 
                               expand_limits(y = 1) + 
                               scale_color_manual(values = colourvector) + 
                               ggtitle("Explanatory Variables After Normalization")
multiplot(p1, p2)

```


```{r}
# running PCA on the normalized counts
sce_seunorm <- runPCA(
  sce_seunorm, ncomponents = 20,
  exprs_values = "counts"
)
```


```{r,  linewidth=60}
# plotting again the PCA's on raw-transformed and normalized values
# raw log-transformation.
tmp <- runPCA(sce_endo, ncomponents = 50, exprs_values = "logcounts_raw")
# PCA plot after log2 transformation
plotPCA(tmp,
        colour_by = params$lab_col,
        size_by = "total_features_by_counts")

# PCA plot after seurat normalization
plotPCA(sce_seunorm,
        colour_by = params$lab_col,
        size_by = "total_features_by_counts")

```


## Build unspliced assay

Select the same cells and genes as in the spliced dataset

```{r build SCE 2}
# df -> matrix -> SCE + phenodata
cells_use <- colnames(sce_endo)
genes_use <- rownames(sce_endo)

sce_us <-
  SingleCellExperiment(
  assays = list(counts = unspliced.data.df),
  colData = pheno_matched,
  rowData = rownames(unspliced.data.df)
  )

control_features_us <- vector("list", 0)
control_features_us_match <- vector("list", 0)

# Dataset after filtering:
sce_usmatch <- sce_us[genes_use,cells_use]

# Adding spike-in information:
if (params$add.spikes.mt) {
  isSpike(sce_us, "MT") <- grepl("^MT-", rownames(sce_us))
  control_features_us[["MT"]] <- isSpike(sce_us, "MT")
  #matched sce object
  isSpike(sce_usmatch, "MT") <- grepl("^MT-", rownames(sce_usmatch))
  control_features_us_match[["MT"]] <- isSpike(sce_usmatch, "MT")
}
if (params$add.spikes.ercc) {
  isSpike(sce_us, "ERCC") <- grepl("^ERCC-", rownames(sce_us))
  control_features_us[["ERCC"]] <- isSpike(sce_us, "ERCC")
  #matched sce object
  isSpike(sce_usmatch, "ERCC") <- grepl("^ERCC-", rownames(sce_usmatch))
  control_features_us_match[["ERCC"]] <- isSpike(sce_usmatch, "ERCC")
}
# Calculate the quality metrics:
# Calculate the quality metrics:
sce_us <- calculateQCMetrics(
  sce_us, feature_controls = control_features_us
    )

sce_usmatch <- calculateQCMetrics(
  sce_usmatch, feature_controls = control_features_us_match
  )
# Arbitrary thresholds:
# Looking at the total number of RNA molecules per sample
# UMI counts were used for this experiment
hist(sce_us$total_counts, breaks = 100)
abline(v = params$total_counts_tresh, col = "red")

# Looking at the amount of unique genes per sample
# This is the amount with ERCC included.
hist(sce_us$total_features_by_counts, breaks = 100)
abline(v= params$total_feat_tresh, col = "red")

hist(sce_usmatch$total_counts, breaks = 100)
abline(v = params$total_counts_tresh, col = "red")
hist(sce_usmatch$total_features_by_counts, breaks = 100)
abline(v= params$total_feat_tresh, col = "red")

pdf(
  paste(
  params$resultsdir,
  "Histograms_before+aftercellsFiltering_UnsplicedReads.pdf",
  sep = "/"
  )
  )
par(mfrow=c(2,2))
hist(sce_us$total_counts, breaks = 100)
abline(v = params$total_counts_tresh, col = "red")
hist(sce_us$total_features_by_counts, breaks = 100)
abline(v= params$total_feat_tresh, col = "red")
hist(sce_usmatch$total_counts, breaks = 100)
abline(v = params$total_counts_tresh, col = "red")
hist(sce_usmatch$total_features_by_counts, breaks = 100)
abline(v= params$total_feat_tresh, col = "red")
dev.off()

```
## Build Seurat object with unspliced and spliced assay

```{r}
unspliced_match <- unspliced.data.df[genes_use,cells_use]
unspliced_match <- as.matrix(unspliced_match)

seu[["uf"]] <- CreateAssayObject(counts = unspliced_match)

seu <- NormalizeData(
    object = seu, assay = "sf",
    normalization.method = "LogNormalize",
    scale.factor = 10000
)
seu <- NormalizeData(
    object = seu, assay = "uf",
    normalization.method = "LogNormalize",
    scale.factor = 10000
)

```


## Highly variable genes & Scaling of the gene expression values

```{r}
# FindVariableFeatures plots the dispersion (= a normalized measure of
# cell-to-cell variation), as a function of average expression for each gene. In
# their tutorial the Satija lab uses the cut-off of 2000 genes.
seu <- FindVariableFeatures(
    object = seu, assay = "sf",
    selection.method = "vst",
    nfeatures = params$nhvg)

seu <- FindVariableFeatures(
    object = seu, assay = "uf",
    selection.method = "vst",
    nfeatures = params$nhvg)

# top 10 most variable genes
top20 <- head(VariableFeatures(seu, assay = "sf"), 20)
top20_uf <- head(VariableFeatures(seu, assay = "uf"), 20)
# plot variable features with labels:
plot1 <- VariableFeaturePlot(seu)
plot2 <- LabelPoints(plot = plot1, points = top20, repel = TRUE)
plot2
plot3 <- VariableFeaturePlot(seu, assay = "uf")
plot4 <- LabelPoints(plot = plot3, points = top20_uf, repel = TRUE)
plot4
# Preferable removing the genes that are highly expressed but with a low variance.
length(x = seu@assays$sf@var.features)
seu[["sf"]]@var.features[1:10]


```

```{r scaling and regressing,  linewidth=60}
# Scaling the data to make it usable for dimensional reduction
# using all the genes, could also select only the highly variable genes.
# Optional regression is performed here.
all.genes <- rownames(seuset)
seu <- ScaleData(
    object = seu,  vars.to.regress = vars_to_regress_sf,
    assay = "sf",
    features = all.genes
)
seu <- ScaleData(
    object = seu,  vars.to.regress =  vars_to_regress_uf,
    assay = "uf",
    features = all.genes
)
```

## Running PCA analysis on the scaled data
```{r running PCA}
seuset <- seu
rm(seu)
DefaultAssay(seuset) <- "sf"
seuset <- RunPCA(
    object = seuset,
    features = VariableFeatures(object = seuset),
    npcs = params$pcs_max_hvg,
    ndims.print = 1:5,
    nfeatures.print = 5
)
length(seuset[["sf"]]@var.features)
length(seuset[["uf"]]@var.features)
```

## Visualizing PCA results:
```{r}
#PrintPCA(object = seuset.scnorm, pcs.print = 1:5, genes.print = 5, use.full = FALSE)

VizDimLoadings(object = seuset, dims = 1:10, reduction = "pca")
VizDimLoadings(object = seuset, dims = 10:20, reduction = "pca")
pdf(paste(
  params$resultsdir,
  paste0("VizPCAplot_PCs1-", params$pcs_max_hvg, ".pdf"),
  sep = "/"
  ),
  width = 20,
  height = 60)
  VizDimLoadings(object = seuset, dims = 1:params$pcs_max_hvg, reduction = "pca")
dev.off()

DimPlot(object = seuset, reduction = "pca", group.by = params$lab_col)

# Helping in choosing the PCs to include in the analysis
DimHeatmap(
    object = seuset,
    dims = 1:5,
    cells = 500,
    balanced = TRUE
)

pdf(paste(
  params$resultsdir,
  paste0("PCheatmap_PCs1-", params$pcs_max_hvg, ".pdf"),
  sep = "/"
  ),
  width = 20,
  height = 60)
  DimHeatmap(
    object = seuset,
    dims = 1:params$pcs_max_hvg,
    cells = 500,
    balanced = TRUE
)
dev.off()
```

## Perform JackStraw Permutations to find significant PCs

```{r running JackStraw}
#seuset.jack <- JackStraw(
#    object = seuset,
#    num.replicate = 100
#)
#seuset.jack <- ScoreJackStraw(seuset.jack, dims = 1:20)
```

```{r}
#JackStrawPlot(object = seuset.jack, dims = 1:20)
```

## Plotting Elbow plot to identify significant PCs
This plot displays the standard deviations of the PCs and the

```{r}
ElbowPlot(object = seuset, ndims = 35)
```

## Overview of different UMAPs with varying dimensional input

```{r}
#Generating a combined UMAP plot with various defined settings. Only a legend in
#the first plotted (since this will be the same for the others). Generating a
#combined plot with only a legend in the first plotted (since this will be the
#same for the others) # This could be done nicer with a loop probably, in which
#for each principle component of interest, there is a umap run, and 2 different
#labels are shown for it.
combine_umap_plot <- function(umap, pcs_for_overview){
  plot.list <- list()
  for (i in (1:length(pcs_for_overview))){
    seuset <- RunUMAP(seuset, dims = 1:pcs_for_overview[i])
    dimnr <- as.character(pcs_for_overview[i])
    print(dimnr)
    if (i == 1){
      plot.list[[dimnr]] <-
        DimPlot(seuset,
        reduction = "umap",
        group.by = umap,
        combine = TRUE) + ggtitle(paste0("UMAP 1:", dimnr))
    } else {
      plot.list[[dimnr]] <-
        DimPlot(seuset,
        reduction = "umap",
        group.by = umap,
        combine = TRUE) + ggtitle(paste0("UMAP 1:", dimnr)) + theme(legend.position = "none")
    }
  }
  #Generate combined plot for umap variabel
  return(plot.list)
}
#Apply to each defined umap component in label vector
for (umap in label.vector) {
  plot.list <- combine_umap_plot(umap, pcs_for_overview)
  pdf(
    paste0(
    params$resultsdir,
    "/",
    "UMAPdiffsettings_",
    paste(as.character(pcs_for_overview), collapse = "-"),
    umap,
    ".pdf"
    ),
    width = 20,
    height = 15
    )
    print(CombinePlots(plot.list, nrows = round(length(pcs_for_overview)/3)))
  dev.off()
}
```

Based on the heatmaps, elbow (as well as the JackStraw indicating these are
significant as well) the first 6 PCs can be used for further analysis.

```{r}
# Saving the dataset with the normalized, scaled and identified HVGs (stored in seuset.scnorm@var.genes).
saveRDS(seuset, file= paste(params$resultsdir,"seusetv3_scnormHVG_velocity.rds", sep="/"))
```


# Now use this file in the Velocyto.R dedicated Conda environment:
# conda activate kb_scrna_velocyto2
